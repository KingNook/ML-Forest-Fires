{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c726972e",
   "metadata": {},
   "source": [
    "# Data Processing Examples\n",
    "Example code for downloading and preparing code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4b2f80",
   "metadata": {},
   "source": [
    "## 0 - Misc Imports\n",
    "Plenty of imports that are generally useful -- imports up here so they don't cause too much clutter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f01d46c",
   "metadata": {},
   "source": [
    "### Important Imports\n",
    "Actually important imports -- make sure these dependencies are installed (will do a requirements.txt at some point); this code block doesn't actually *have* to be run; any required imports will be at the top of each code block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f420b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0569d4b",
   "metadata": {},
   "source": [
    "#### Environment Settings\n",
    "To be honest, I have no clue where this is supposed to go (like idk what is causing errors), but this **does** need to be run at some point before the rest of the code ðŸ˜Š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37ce747",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['SCIKIT_ARRAY_API'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe89eceb",
   "metadata": {},
   "source": [
    "### Optional Import(s)\n",
    "Intel has put out the `sklearnex` module which provides speed ups for training of sklearn models on Intel CPUs. If this is not relevant, ignore this section. If this section raises errors, also just skip it; it provides a speed up but the functionality is completely unaffected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e403a337",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearnex import patch_sklearn\n",
    "patch_sklearn()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5fe5a01",
   "metadata": {},
   "source": [
    "## 1 - Download + Pre-Process\n",
    "Essentially example code for `forest_fire/prepare_data`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce4852cb",
   "metadata": {},
   "source": [
    "First, we need to download the data -- in my experience this tends to take circa 10-12 ish minutes per month of data, so for 5 years, that adds up to around 6 hours (I think). In other words, probably set this cell off and leave it going in the background.\n",
    "\n",
    "DO NOTE THAT this currently only downloads the training data (2010-2014); downloading test data (2015-2019) requires changes to the code.\n",
    "\n",
    "Either:\n",
    "1. Change `request_total_data` to request all 10 years of data at once, or\n",
    "2. Make a second request for the test data\n",
    "\n",
    "I have gone with 2. while doing the project, but 1. might be more efficient, with the small caveat that it is a bit of a pain if the download is interrupted partway. Note that in the second case, the training data can be used as the prior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a7d920",
   "metadata": {},
   "outputs": [],
   "source": [
    "from forest_fire.prepare_data.CDS_requests import request_total_data\n",
    "\n",
    "## USE CANADA RANGE AS EXAMPLE\n",
    "from forest_fire.prepare_data.extents import CANADA_RICHARDSON_EXTENT\n",
    "\n",
    "request_total_data(\n",
    "    extent = CANADA_RICHARDSON_EXTENT,\n",
    "    data_path = './data'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f3a39b",
   "metadata": {},
   "source": [
    "By default, the above code block will download our data to `data/canada/main/combined.grib` and `data/canada/prior/combined.grib`\n",
    "\n",
    "For future reference, it'll be much quicker to have this data in the form of Zarr groups instead of grib files, so we do that next -- in fairness, this step isn't entirely necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb38d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from forest_fire.prepare_data.process_data import grib_to_zarr\n",
    "\n",
    "grib_to_zarr(grib_path = 'data/canada/main/combined.grib', zarr_path = 'data/canada/main/', name = '_ZARR')\n",
    "grib_to_zarr(grib_path = 'data/canada/prior/combined.grib', zarr_path = 'data/canada/prior', name = '_ZARR')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ae10e8",
   "metadata": {},
   "source": [
    "We now need to **setup** the data -- for this we have the `setup_dataset()` function from `process_data.py`. We will write this prepared dataset to storage as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b81747c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from forest_fire.prepare_data.process_data import setup_dataset\n",
    "\n",
    "PROXIES = {\n",
    "    'tp': (30, 90, 180),\n",
    "    't2m': (30, 90, 180)\n",
    "}\n",
    "\n",
    "setup_dataset(\n",
    "    main_path = 'data/canada/main/_ZARR',\n",
    "    prior_path = 'data/canada/prior/_ZARR',\n",
    "    proxy_config = PROXIES\n",
    ").to_zarr(\n",
    "    store = 'data/canada/ZARR_READY'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f7cd08",
   "metadata": {},
   "source": [
    "Any further manipulation of data is then handled in `forest_fire/train`. You can also restart the kernel at this point to clear stored variables if you so wish -- just remember to re-import modules from section 0!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e746a5c",
   "metadata": {},
   "source": [
    "## 2 - Model Training\n",
    "Example code for `forest_fire/train` + examples of models used for this project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f817d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from forest_fire.train.prepare_samples import prep_samples\n",
    "\n",
    "train_ds = xr.open_zarr(\n",
    "    'data/canada/ZARR_READY'\n",
    ")\n",
    "\n",
    "X, y = prep_samples(\n",
    "    ds = train_ds\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed30f7c4",
   "metadata": {},
   "source": [
    "### Resampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97eb27e7",
   "metadata": {},
   "source": [
    "This generally works fine. However, the data for this project has tended to be wildly imbalanced (with around a 1:10000 ratio of negative-positive points being fairly common). Therefore, up/downsampling has been used on the training data. This has been done using the `imblearn` module.\n",
    "\n",
    "Downsampling was done with `RandomUnderSampler` (bootstrapped samples), while upsampling was done with a mix of `ADASYN` and `SMOTE`. Example code for this is provided below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42a6878",
   "metadata": {},
   "source": [
    "#### Downsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01a1027",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "downsampler = RandomUnderSampler(sampling_strategy = 0.1)\n",
    "\n",
    "X_down, y_down = downsampler.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f70de0b",
   "metadata": {},
   "source": [
    "#### Upsampling\n",
    "Examples are provided for both SMOTE and ADASYN; there is more work to be done on comparing which is better in various cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5dc452",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''SMOTE'''\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "SMOTE_oversampler = SMOTE(sampling_strategy = 0.1)\n",
    "\n",
    "X_smote, y_smote = SMOTE_oversampler.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8a0df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''ADASYN'''\n",
    "from imblearn.over_sampling import ADASYN\n",
    "\n",
    "ADASYN_oversampler = ADASYN(sampling_strategy = 0.1)\n",
    "\n",
    "X_ada, y_ada = ADASYN_oversampler.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d9864fc",
   "metadata": {},
   "source": [
    "### Training\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_ff",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
